{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ios.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hanolda/learning-election-winners/blob/master/ios.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "IOVF5y89YagL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Sep 26 12:48:29 2018\n",
        "\n",
        "@author: hkujawska\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "This module should contain project specific io functionality.\n",
        "Loading and saving of files should be deferred to this class for easy and consistent file handling between different\n",
        "sources and to have a single location where file references are held.\n",
        "\"\"\"\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "class IO:\n",
        "    cleaned_file_remote = '/content/drive/AggregationVotesProjectSpotify/data/demofile1.csv'\n",
        "    cleaned_file_local = '/content/drive/AggregationVotesProjectSpotify/data/demofile1.csv'\n",
        "    local_data_path = '.'\n",
        "\n",
        "    def __init__(self, local_data_path: str):\n",
        "        \"\"\"\n",
        "        Constructor that can set the data path from where we will access local data..\n",
        "        Args:\n",
        "            path: Path to the data folder.\n",
        "        \"\"\"\n",
        "        self.local_data_path = local_data_path\n",
        "\n",
        "    def load_cleaned_file(self, download_always: bool = True):\n",
        "        \"\"\"\n",
        "        Load the cleaned file, optionally logging into to Azure to download.\n",
        "        If token is passed then this will only login if token isn't already valid\n",
        "        Args:\n",
        "            download_always: Whether to always download the file even if it exists locally\n",
        "        Returns:\n",
        "            A dataframe used for logging in and the login token\n",
        "        \"\"\"\n",
        "        local_path = os.path.join(self.local_data_path, self.cleaned_file_local)\n",
        "\n",
        " #       token = datalake.login_and_download_file(self.cleaned_file_remote,\n",
        " #                                                local_path,\n",
        " #                                                download_always=download_always)\n",
        "\n",
        "        df = pd.read_csv(local_path)#, sep='\\r', header = None)#,\n",
        "                        # dtype={'Well_name': 'category'},\n",
        "                        # parse_dates=['start'])\n",
        "        return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}